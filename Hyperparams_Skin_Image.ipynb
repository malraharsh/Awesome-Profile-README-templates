{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparams-Skin-Image.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "U7jmsbwzYruB"
      ],
      "mount_file_id": "1AxbaFtVVJd0Qr-2Tm6X9qLiDJFFIhe6f",
      "authorship_tag": "ABX9TyPp/PRHCqt6v6Dl87AEUaNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malraharsh/Awesome-Profile-README-templates/blob/master/Hyperparams_Skin_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EahncA97pFvB"
      },
      "source": [
        ""
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N-IepYGTmlu"
      },
      "source": [
        "DO_GET_Images = True\n",
        "DO_TFRecord = True"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9nlzm-6TDSu"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBw4l30ELTuZ",
        "cellView": "form"
      },
      "source": [
        "#@title Importing Libraries\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "import scipy.ndimage\n",
        "from scipy import misc\n",
        "from glob import glob\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import skimage\n",
        "import imageio\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import scikitplot as skplt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "%matplotlib inline"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysS4ZiUCKSYp"
      },
      "source": [
        "# shutil.make_archive('tfrecord', 'zip', 'tfrecord')"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjL60qm2KsHF"
      },
      "source": [
        "# !cp tfrecord.zip /content/drive/MyDrive/Internship/tfrecord.zip"
      ],
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImnWVwfJS0vc",
        "cellView": "code"
      },
      "source": [
        "#@title\n",
        "%mkdir -p others data"
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ6V-Q7Y3xkP"
      },
      "source": [
        "path_drive_data = '/content/drive/MyDrive/Internship/'\n",
        "path_images = '/content/Images'\n",
        "path_drive_models = '/content/drive/MyDrive/Files/dermasync/'"
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av7fFbrVxQ7E"
      },
      "source": [
        ""
      ],
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_EqPHcC_8zH"
      },
      "source": [
        "import shutil"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzIO3e-uziBU",
        "cellView": "code"
      },
      "source": [
        "%%capture\n",
        "if DO_GET_Images:\n",
        "    if os.path.isdir(path_images): shutil.rmtree(path_images)\n",
        "    !cp -n '/content/drive/MyDrive/Internship/Images-Full-Combined.rar' /content/others/\n",
        "    if not os.path.isdir('/content/Images'):\n",
        "        !unrar x '/content/others/Images-Full-Combined.rar'"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ6fJ_HoUHme"
      },
      "source": [
        "!cp -n /content/drive/MyDrive/Internship/*.csv /content/data/\n",
        "# !cp -n '/content/drive/MyDrive/Internship/tfrecord.zip.zip' /content/others/"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S1VWKoK17bC",
        "cellView": "code"
      },
      "source": [
        "%%capture\n",
        "if not os.path.isdir('/content/tfrecord'):\n",
        "    !unzip -o '/content/others/tfrecord.zip.zip' -d 'tfrecord'"
      ],
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW9UHl6XSmcn"
      },
      "source": [
        "path_data = '/content/Images'"
      ],
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYK32NJATL-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f0b084-8f1b-4fe8-c6a5-bf35818f2d5e"
      },
      "source": [
        "skin_labels = ['Acne', 'Alopecia', 'Chancroid', 'Contact Dermatitis', \n",
        "          'Corns and Calluses', 'Distal-Subungual-Onychomycosis', \n",
        "          'Drug Eruption', 'Folliculitis', 'Genital Warts', \n",
        "          'Guttate Psoriasis', 'Halo Nevus', 'Hemangioma',\n",
        "          'Herpes Simplex', 'Ichthyosis', 'Impetigo', 'Keloid Scar', \n",
        "          'Leprosy', 'Litchen Planus', 'Litchen Simplex Chronicus', \n",
        "          'Melasma', 'Molluscum Contagiosum', 'Nummular Dermatitis',\n",
        "          'Onychomycosis', 'Photocontact Dermatitis', 'Pityriasis Alba',\n",
        "          'Pityriasis Rosea', 'Pityriasis Versicolor', 'Plaque Psoriasis',\n",
        "          'Polymorphic Light Eruption', 'Ringworm of Body',\n",
        "          'Ringworm of Face', 'Ringworm of Hands', 'Ringworm of Scalp',\n",
        "          'Scabies', 'Seborrheic Dermatitis', 'Syphilis', 'Tinea Cruris',\n",
        "          'Urticaria', 'Vitiligo', 'Warts']\n",
        "\n",
        "skin_labels = ['Warts', 'Herpes Simplex', 'Acne',  'Halo Nevus']\n",
        "\n",
        "skin_labels = ['Warts', 'Herpes Simplex', 'Guttate Psoriasis', 'Halo Nevus', 'Acne',\n",
        "       'Folliculitis', 'Nummular Dermatitis', 'Hemangioma', 'Drug Eruption',\n",
        "       'Melasma', 'Pityriasis Rosea', 'Tinea Cruris', 'Scabies', 'Impetigo',\n",
        "       'Corns and Calluses', 'Contact Dermatitis', 'Molluscum Contagiosum',\n",
        "       'Urticaria', 'Litchen Planus', 'Keloid Scar', 'Alopecia'\n",
        "       'Ringworm of Body', 'Ringworm of Hands', 'Litchen Simplex Chronicus',\n",
        "       'Plaque Psoriasis', 'Ichthyosis', 'Pityriasis Versicolor',\n",
        "       'Seborrheic Dermatitis', 'Ringworm of Face',\n",
        "       'Polymorphic Light Eruption', 'Pityriasis Alba', 'Onychomycosis',\n",
        "       'Photocontact Dermatitis', 'Vitiligo', 'Ringworm of Scalp', 'Syphilis',\n",
        "       'Distal-Subungual-Onychomycosis']\n",
        "\n",
        "skin_labels = sorted(skin_labels)\n",
        "print(len(skin_labels))"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEJ-J0MZq6ro"
      },
      "source": [
        "path_root = '/content/'\n",
        "path_dest = '/content/destination'\n",
        "path_train = path_root + 'train'\n",
        "path_test = path_root + 'test'\n",
        "path_images = 'Images/'"
      ],
      "execution_count": 341,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYxZHaXx9nM9"
      },
      "source": [
        "for label in os.listdir(path_images):\n",
        "    if label in skin_labels: continue\n",
        "    p = os.path.join(path_images, label)    \n",
        "    shutil.rmtree(p)"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXAzvCWj8Aqk"
      },
      "source": [
        "path_images_csv = '/content/data/df_path_images.csv'\n",
        "if os.path.isfile(path_images_csv):\n",
        "    df_path_images = pd.read_csv(path_images_csv)\n",
        "else:\n",
        "    df_path_images = pd.DataFrame({'disease': [], 'path': []})\n",
        "    for path_img in glob.glob('Images/*/*.jpg'):\n",
        "        path_split = path_img.split('/')\n",
        "        disease = path_split[1]\n",
        "        path_img = '/'.join(path_split[1:])\n",
        "        df_path_images = df_path_images.append(dict(disease=disease, path=path_img), ignore_index=True)"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfFg9HkjPosv"
      },
      "source": [
        "# df_path_images.disease.value_counts().keys()"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dElrgF_jFTQ"
      },
      "source": [
        "# balance\n",
        "from sklearn.utils import resample#split data into test and training sets\n",
        "\n",
        "def upsample_data(df, by='Skin Problem'):\n",
        "    # by - using by skin problem, so count is same, data balancing\n",
        "    # cols - unique values in by\n",
        "    cols = df[by].unique()\n",
        "    max_count = max(df[by].value_counts()) # larget category\n",
        "    df_up = pd.DataFrame() # upsampled\n",
        "    for col in cols:\n",
        "        df_col = df.loc[df[by]==col] # data of particular disease\n",
        "        upsampled = resample(df_col, replace=True, n_samples=max_count, random_state=42)\n",
        "        df_up = pd.concat([df_up, upsampled])\n",
        "    return df_up"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdCz3uewTLne"
      },
      "source": [
        "preprocess_input_image = tf.keras.applications.mobilenet.preprocess_input"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bWQNL8yTcWR"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCz-WDbWVQUY"
      },
      "source": [
        "df = df_path_images.copy()"
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15T9WmN53CBW"
      },
      "source": [
        "df = df[df.disease.isin(skin_labels)]\n",
        "df = df.reset_index()"
      ],
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5cZh0mq3AyO"
      },
      "source": [
        "cnts = df.disease.value_counts()\n",
        "import math"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTIKrUVDXTMV"
      },
      "source": [
        "### removing dis having less than n images\n",
        "\n",
        "min_images = 0\n",
        "disease_drop = cnts[cnts < min_images].index\n",
        "idx_drop = df[df.disease.isin(disease_drop)].index\n",
        "df.drop(index=idx_drop, inplace=True)\n",
        "df_orig = df.copy()"
      ],
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zflzCKm9hLFp"
      },
      "source": [
        "skin_labels = sorted(df.disease.unique())"
      ],
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58xWGi2YpPxj"
      },
      "source": [
        "### removing more than keep num images, for class balance\n",
        "\n",
        "def keep_n_images(keep_n, df):\n",
        "    for label in skin_labels:\n",
        "        idxs = df[df.disease == label].index\n",
        "        idxs_drop = idxs[keep_n:]\n",
        "        df = df.drop(index=idxs_drop)\n",
        "    return df"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh67fOmVjsxS",
        "outputId": "7d593cf5-aad0-46df-902f-cd66c38ec96a"
      },
      "source": [
        "df.disease.value_counts()"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Warts                             916\n",
              "Herpes Simplex                    840\n",
              "Guttate Psoriasis                 753\n",
              "Halo Nevus                        681\n",
              "Acne                              646\n",
              "Folliculitis                      629\n",
              "Nummular Dermatitis               628\n",
              "Hemangioma                        527\n",
              "Drug Eruption                     468\n",
              "Melasma                           464\n",
              "Pityriasis Rosea                  443\n",
              "Tinea Cruris                      441\n",
              "Scabies                           438\n",
              "Impetigo                          437\n",
              "Corns and Calluses                431\n",
              "Contact Dermatitis                428\n",
              "Molluscum Contagiosum             422\n",
              "Urticaria                         402\n",
              "Litchen Planus                    398\n",
              "Keloid Scar                       379\n",
              "Ringworm of Hands                 349\n",
              "Litchen Simplex Chronicus         341\n",
              "Plaque Psoriasis                  339\n",
              "Ichthyosis                        320\n",
              "Seborrheic Dermatitis             304\n",
              "Pityriasis Versicolor             304\n",
              "Ringworm of Face                  303\n",
              "Polymorphic Light Eruption        298\n",
              "Pityriasis Alba                   277\n",
              "Photocontact Dermatitis           231\n",
              "Onychomycosis                     231\n",
              "Vitiligo                          171\n",
              "Ringworm of Scalp                 145\n",
              "Syphilis                          144\n",
              "Distal-Subungual-Onychomycosis    126\n",
              "Name: disease, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVeR5YM3_J-I"
      },
      "source": [
        "df_data = df"
      ],
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz8be-52QkHK"
      },
      "source": [
        "# Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPH-7GDb-p22"
      },
      "source": [
        "# df_data = keep_n_images(250, df_data)\n",
        "\n",
        "df_train, df_val = train_test_split(df_data, test_size=0.01,\n",
        "                                    random_state=42, \n",
        "                                    stratify=df_data['disease'])\n",
        "\n",
        "df_train = upsample_data(df_train, by='disease')\n",
        "\n",
        "df_test = df_val"
      ],
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzmrKHsBr-Lz"
      },
      "source": [
        "batch_size = max(32, len(skin_labels) * 2)\n",
        "                 \n",
        "num_train_samples = len(df_train)\n",
        "num_test_samples = len(df_test)\n",
        "train_batch_size = batch_size\n",
        "test_batch_size = batch_size\n",
        "IMAGE_SHAPE = image_shape = (224, 224)"
      ],
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk6OGXvv8ohl"
      },
      "source": [
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "test_steps = np.ceil(num_test_samples / test_batch_size)"
      ],
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6bd1ZGbsNFu",
        "outputId": "a95aa9c1-43b2-4450-f173-99c86cd2286f"
      },
      "source": [
        "def get_batches_train(shuffle=True):\n",
        "    datagen_train = ImageDataGenerator(\n",
        "            rotation_range=30,\n",
        "            # rescale=1. / 255,\n",
        "            width_shift_range=0.3,\n",
        "            height_shift_range=0.3,\n",
        "            zoom_range=0.3,\n",
        "            horizontal_flip=True,\n",
        "            # vertical_flip=True,\n",
        "            # brightness_range=(0.9,1.1),\n",
        "            fill_mode='nearest',\n",
        "            # preprocessing_function= preprocess_input_image\n",
        "            )\n",
        "\n",
        "    batches_train = datagen_train.flow_from_dataframe(\n",
        "                                    dataframe=df_train,\n",
        "                                    directory=path_data,\n",
        "                                    x_col='path',\n",
        "                                    y_col='disease',\n",
        "                                    # subset=\"training\",\n",
        "                                    batch_size=train_batch_size,\n",
        "                                    seed=42,\n",
        "                                    shuffle=shuffle,\n",
        "                                    class_mode=\"sparse\",\n",
        "                                    target_size=image_shape)\n",
        "\n",
        "    return batches_train\n",
        "\n",
        "def get_batches_test(df_test=df_test):        \n",
        "    datagen_test = ImageDataGenerator(\n",
        "                                    #   rescale=1. / 255,\n",
        "                                    #   preprocessing_function= preprocess_input_image\n",
        "                                      )\n",
        "\n",
        "    batches_test = datagen_test.flow_from_dataframe(\n",
        "                                    dataframe=df_test,\n",
        "                                    directory=path_data,\n",
        "                                    x_col='path',\n",
        "                                    y_col='disease',\n",
        "                                    # subset=\"training\",\n",
        "                                    batch_size=test_batch_size,\n",
        "                                    seed=42,\n",
        "                                    shuffle=False,\n",
        "                                    class_mode=\"sparse\",\n",
        "                                    target_size=image_shape)\n",
        "    \n",
        "    return batches_test\n",
        "\n",
        "batches_train = get_batches_train()\n",
        "batches_test = get_batches_test()"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 31745 validated image filenames belonging to 35 classes.\n",
            "Found 147 validated image filenames belonging to 35 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoAk8ZlDYp-R"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(batches_train.classes),\n",
        "                                                 batches_train.classes)\n",
        "class_weights = dict(enumerate(class_weights))"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K7035QEVSrU",
        "outputId": "b3df175a-2c92-4adb-bca3-952ee552166b"
      },
      "source": [
        "path_images = 'Images/'\n",
        "# nb_images=len(tf.io.gfile.glob(path_images + '*/*.jpg'))\n",
        "nb_images = df_data.shape[0]\n",
        "print(tf.__version__)\n",
        "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
        "\n",
        "CLASSES = [file.encode() for file in skin_labels]\n",
        "# nb_images=len(tf.io.gfile.glob('data/*/*.jpeg'))\n",
        "SHARDS = 16\n",
        "shared_size = math.ceil(1.0 * nb_images / SHARDS) # batch size of tfrecord\n",
        "# print(shared_size)\n",
        "\n",
        "TARGET_SIZE=224\n",
        "\n",
        "path_images_train = path_images + df_train.path.values"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMyoBp2BL8rb"
      },
      "source": [
        "# TFRecord"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyv1C8GpuOzM"
      },
      "source": [
        "import math\n",
        "\n",
        "def read_image_and_label(img_path):\n",
        "  \n",
        "  bits = tf.io.read_file(img_path)\n",
        "  image = tf.image.decode_jpeg(bits)  \n",
        "  image = tf.image.resize(image, [TARGET_SIZE, TARGET_SIZE])\n",
        "\n",
        "  label = tf.strings.split(img_path, sep='/')[-2]\n",
        "#   assert(len(label) > 1) # to make sure sep is correct\n",
        "  return image, label"
      ],
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYNb2hUkubtE"
      },
      "source": [
        "def compress_image(image, label):\n",
        "  image = tf.cast(image, tf.uint8)\n",
        "  image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n",
        "  return image, label\n",
        "\n",
        "def _bytestring_feature(list_of_bytestrings):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
        "\n",
        "def _int_feature(list_of_ints): # int64\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
        "\n",
        "def _float_feature(list_of_floats): # float32\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))\n",
        "\n",
        "def to_tfrecord(img_bytes, label):  \n",
        "  class_num = np.argmax(np.array(CLASSES)==label) \n",
        "  feature = {\n",
        "      \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
        "      \"class\": _int_feature([class_num]),        # one class in the list      \n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n"
      ],
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYS1Q0squfkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eaaa579-3a3b-43ba-894e-1ae962555e13"
      },
      "source": [
        "dataset = tf.data.Dataset.list_files(path_images_train, seed=10000) # This also shuffles the images\n",
        "dataset = dataset.map(read_image_and_label)\n",
        "dataset = dataset.map(compress_image, num_parallel_calls=AUTO)\n",
        "dataset = dataset.batch(shared_size) \n",
        "\n",
        "if DO_TFRecord or not os.path.exists('tfrecord'):\n",
        "    if os.path.exists('tfrecord'): shutil.rmtree('tfrecord')\n",
        "    os.mkdir('tfrecord')\n",
        "    for shard, (image, label) in enumerate(dataset):\n",
        "        shard_size = image.numpy().shape[0]\n",
        "        filename = \"tfrecord/\" + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
        "\n",
        "        with tf.io.TFRecordWriter(filename) as out_file:\n",
        "            for i in range(shard_size):\n",
        "            #       print(label.numpy()[i])  \n",
        "                example = to_tfrecord(image.numpy()[i],label.numpy()[i])\n",
        "                out_file.write(example.SerializeToString())\n",
        "        print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrote file tfrecord/00-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/01-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/02-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/03-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/04-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/05-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/06-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/07-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/08-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/09-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/10-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/11-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/12-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/13-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/14-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/15-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/16-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/17-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/18-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/19-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/20-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/21-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/22-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/23-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/24-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/25-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/26-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/27-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/28-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/29-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/30-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/31-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/32-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/33-916.tfrec containing 916 records\n",
            "Wrote file tfrecord/34-601.tfrec containing 601 records\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnWtwueKODWB",
        "cellView": "form"
      },
      "source": [
        "#@title Visualization Utitlites\n",
        "# numpy and matplotlib defaults\n",
        "np.set_printoptions(threshold=15, linewidth=80)\n",
        "# https://www.kaggle.com/mgornergoogle/getting-started-with-100-flowers-on-tpu\n",
        "def batch_to_numpy_images_and_labels(data):\n",
        "    images, labels = data\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()\n",
        "    if numpy_labels.dtype == object: # binary string in this case, these are image ID strings\n",
        "        numpy_labels = [None for _ in enumerate(numpy_images)]\n",
        "    # If no labels, only image IDs, return None for labels (this is the case for test data)\n",
        "    return numpy_images, numpy_labels\n",
        "\n",
        "def title_from_label_and_target(label, correct_label):\n",
        "    if correct_label is None:\n",
        "        return CLASSES[label], True\n",
        "    correct = (label == correct_label)\n",
        "    return \"{} [{}{}{}]\".format(CLASSES[label], 'OK' if correct else 'NO', u\"\\u2192\" if not correct else '',\n",
        "                                CLASSES[correct_label] if not correct else ''), correct\n",
        "\n",
        "def display_one_flower(image, title, subplot, red=False, titlesize=16):\n",
        "    plt.subplot(*subplot)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "    if len(title) > 0:\n",
        "        plt.title(title, fontsize=int(titlesize) if not red else int(titlesize/1.2), color='red' if red else 'black', fontdict={'verticalalignment':'center'}, pad=int(titlesize/1.5))\n",
        "    return (subplot[0], subplot[1], subplot[2]+1)\n",
        "    \n",
        "def display_batch_of_images(databatch, predictions=None):\n",
        "    \"\"\"This will work with:\n",
        "    display_batch_of_images(images)\n",
        "    display_batch_of_images(images, predictions)\n",
        "    display_batch_of_images((images, labels))\n",
        "    display_batch_of_images((images, labels), predictions)\n",
        "    \"\"\"\n",
        "    # data\n",
        "    images, labels = batch_to_numpy_images_and_labels(databatch)\n",
        "    if labels is None:\n",
        "        labels = [None for _ in enumerate(images)]\n",
        "        \n",
        "    # auto-squaring: this will drop data that does not fit into square or square-ish rectangle\n",
        "    rows = int(math.sqrt(len(images)))\n",
        "    cols = len(images)//rows\n",
        "        \n",
        "    # size and spacing\n",
        "    FIGSIZE = 13.0\n",
        "    SPACING = 0.1\n",
        "    subplot=(rows,cols,1)\n",
        "    if rows < cols:\n",
        "        plt.figure(figsize=(FIGSIZE,FIGSIZE/cols*rows))\n",
        "    else:\n",
        "        plt.figure(figsize=(FIGSIZE/rows*cols,FIGSIZE))\n",
        "    \n",
        "    # display\n",
        "    for i, (image, label) in enumerate(zip(images[:rows*cols], labels[:rows*cols])):\n",
        "        title = '' if label is None else CLASSES[label]\n",
        "        correct = True\n",
        "        if predictions is not None:\n",
        "            title, correct = title_from_label_and_target(predictions[i], label)\n",
        "        dynamic_titlesize = FIGSIZE*SPACING/max(rows,cols)*40+3 # magic formula tested to work from 1x1 to 10x10 images\n",
        "        subplot = display_one_flower(image, title, subplot, not correct, titlesize=dynamic_titlesize)\n",
        "    \n",
        "    #layout\n",
        "    plt.tight_layout()\n",
        "    if label is None and predictions is None:\n",
        "        plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    else:\n",
        "        plt.subplots_adjust(wspace=SPACING, hspace=SPACING)\n",
        "    plt.show()\n",
        "\n",
        "def display_confusion_matrix(cmat, score, precision, recall):\n",
        "    plt.figure(figsize=(15,15))\n",
        "    ax = plt.gca()\n",
        "    ax.matshow(cmat, cmap='Reds')\n",
        "    ax.set_xticks(range(len(CLASSES)))\n",
        "    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n",
        "    ax.set_yticks(range(len(CLASSES)))\n",
        "    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n",
        "    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
        "    titlestring = \"\"\n",
        "    if score is not None:\n",
        "        titlestring += 'f1 = {:.3f} '.format(score)\n",
        "    if precision is not None:\n",
        "        titlestring += '\\nprecision = {:.3f} '.format(precision)\n",
        "    if recall is not None:\n",
        "        titlestring += '\\nrecall = {:.3f} '.format(recall)\n",
        "    if len(titlestring) > 0:\n",
        "        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n",
        "    plt.show()\n",
        "    \n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udMojSirtr1b"
      },
      "source": [
        "\n",
        "def decode_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.cast(image, tf.float32) #/ 255.0\n",
        "    # image = preprocess_input_image(image)\n",
        "    # image = tf.reshape(image, [TARGET_SIZE,TARGET_SIZE, 3])\n",
        "    return image\n",
        "\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    features = {\n",
        "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
        "        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
        "    }\n",
        "    # decode the TFRecord\n",
        "    example = tf.io.parse_single_example(example, features)   \n",
        "    image = decode_image(example['image']) \n",
        "    class_label = tf.cast(example['class'], tf.int32)\n",
        "    # label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, class_label\n",
        "\n",
        "def data_augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    # image = tf.image.rot90(image, k=1) # rotate 90º\n",
        "    # image = tf.image.random_crop(image, (200, 200, 3))\n",
        "    image = tf.image.random_brightness(image, max_delta=.3)\n",
        "    # image = tf.image.random_jpeg_quality(image, 70, 100)\n",
        "    return image, label\n",
        "\n",
        "def get_batched_dataset(filenames, augment=False, shuffle=False, cache=False):\n",
        "  option_no_order = tf.data.Options()\n",
        "  option_no_order.experimental_deterministic = False\n",
        "\n",
        "  dataset = tf.data.Dataset.list_files(filenames)\n",
        "  dataset = dataset.with_options(option_no_order)\n",
        "  dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
        "  dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
        "  if augment:\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n",
        "  if cache:\n",
        "      dataset = dataset.cache() # This dataset fits in RAM\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(2048)\n",
        "  dataset = dataset.repeat()\n",
        " \n",
        "  dataset = dataset.batch(BATCH_SIZE) #, drop_remainder=True) # drop_remainder will be needed on TPU\n",
        "\n",
        "  dataset = dataset.prefetch(AUTO) \n",
        "  return dataset\n",
        "  \n",
        "\n",
        "def get_training_dataset(augment=True, cache=False):\n",
        "  return get_batched_dataset(training_filenames, shuffle=True, augment=augment, cache=cache)\n",
        "\n",
        "def get_validation_dataset():\n",
        "  return get_batched_dataset(validation_filenames)\n",
        "\n",
        "AUTO = AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qngx1cs7OYUt"
      },
      "source": [
        "# training_dataset = get_training_dataset()\n",
        "# training_dataset = training_dataset.unbatch().batch(8)\n",
        "# train_batch = iter(training_dataset)\n",
        "# # run this cell again for next set of images\n",
        "# display_batch_of_images(next(train_batch))"
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo4qxcHGTHnF"
      },
      "source": [
        ""
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXxvBn4KjI23"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeVUh8oelm1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e0d5d2-1afc-4477-d579-c0fc1f8e9bd0"
      },
      "source": [
        "import glob\n",
        "import os, json, random\n",
        "\n",
        "VALIDATION_SPLIT = 0.07\n",
        "\n",
        "BATCH_SIZE = batch_size\n",
        "\n",
        "filenames=tf.io.gfile.glob('tfrecord/*.tfrec')\n",
        "\n",
        "random.shuffle(filenames)\n",
        "split = int(len(filenames) * VALIDATION_SPLIT)\n",
        "\n",
        "training_filenames = filenames[split:]\n",
        "validation_filenames = filenames[:split]\n",
        "\n",
        "validation_steps = int(nb_images // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(nb_images // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
        "\n",
        "print(int(nb_images * (VALIDATION_SPLIT)))\n",
        "assert(split >= 1 and validation_steps>=1)"
      ],
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl5177lN7z4D"
      },
      "source": [
        "def create_base_model(k=0):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape = (224,224,3)))\n",
        "    model.add(tf.keras.layers.Lambda(preprocess_input_image))\n",
        "    base_model = tf.keras.applications.mobilenet.MobileNet(input_shape=(224, 224, 3), include_top=False)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    if k > 0:    \n",
        "        for layer in base_model.layers[-k:]:\n",
        "            layer.trainable = True   \n",
        "    model.add(base_model)\n",
        "    return model\n",
        "\n",
        "def create_model():\n",
        "    top = tf.keras.Sequential()\n",
        "    top.add(Flatten())\n",
        "    top.add(Dense(512, activation = 'relu'))\n",
        "    top.add(BatchNormalization())\n",
        "    top.add(Dropout(0.5))\n",
        "    top.add(Dense(256, activation = 'relu'))\n",
        "    top.add(BatchNormalization())\n",
        "    top.add(Dropout(0.5))\n",
        "    top.add(Dense(256, activation = 'relu'))\n",
        "    top.add(BatchNormalization())\n",
        "    top.add(Dropout(0.5))\n",
        "    top.add(Dense(128, activation = 'relu'))\n",
        "    top.add(BatchNormalization())\n",
        "    top.add(Dropout(0.25))\n",
        "    top.add(Dense(len(labels), activation = 'softmax'))\n",
        "\n",
        "    base_model = create_base_model()\n",
        "    x = base_model.output\n",
        "    outputs = top(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "filepath = \"/content/model.h5\"\n",
        "\n",
        "def get_model(params=None, lr=None):\n",
        "    if params:\n",
        "        model = create_model_adv(**params)\n",
        "    else:\n",
        "        model = create_model()\n",
        "\n",
        "    model.compile(Adam(lr=lr), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='sparse_categorical_accuracy', verbose=1,\n",
        "                                save_best_only=True, mode='max')\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='sparse_categorical_accuracy', factor=0.5, patience=2,\n",
        "                                verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='sparse_categorical_accuracy', patience=5)\n",
        "\n",
        "    callbacks = [checkpoint, reduce_lr, early_stop]\n",
        "\n",
        "    return model, callbacks\n",
        "# model, callbacks = get_model()"
      ],
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozb1oi951pGL"
      },
      "source": [
        "# !cp /content/drive/MyDrive/Files/dermasync/model_tfr.h5 /content/model.h5\n",
        "# model.load_weights('/content/model.h5')\n",
        "\n",
        "# model = tf.keras.models.load_model('model.h5', compile=False)\n",
        "\n",
        "# def create_model_adv(n_conv_layers, n_filters, k, n_dense_layers, n_dense_units, c_dropout, use_base=True):\n",
        "#     model = tf.keras.Sequential()\n",
        "#     if not use_base: model.add(tf.keras.layers.Input(shape=(224,224,3)))\n",
        "#     model.add(tf.keras.layers.Lambda(preprocess_input_image))\n",
        "\n",
        "#     for i in range(1, n_conv_layers + 1):\n",
        "#         add_conv_layers(model, n_filters * i, c_dropout)\n",
        "\n",
        "#     model.add(Flatten())\n",
        "    \n",
        "#     for i in range(1, n_dense_layers): # n - 1\n",
        "#         add_dense_layers(model, n_dense_units, c_dropout)\n",
        "\n",
        "#     model.add(Dense(len(skin_labels), activation = 'softmax'))\n",
        "#     # print(model.summary())\n",
        "#     if not use_base: return model\n",
        "#     base_model = create_base_model(k)\n",
        "#     x = base_model.output\n",
        "#     outputs = model(x)\n",
        "#     merged_model = Model(inputs=base_model.input, outputs=outputs)\n",
        "#     return merged_model\n",
        "# history = model.fit(batches_train,\n",
        "#                      steps_per_epoch=train_steps,\n",
        "#                      class_weight=class_weights,\n",
        "#                      validation_data=batches_test,\n",
        "#                      validation_steps=test_steps,\n",
        "#                      epochs=5,\n",
        "#                      # shuffle=True,#\n",
        "#                      verbose=1,\n",
        "#                      callbacks=callbacks,\n",
        "#                      )"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGC49smdmoRS"
      },
      "source": [
        ""
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftvXcTYDAdgw"
      },
      "source": [
        "## model, callbacks = get_model(study.best_params)\n",
        "# model, callbacks = get_model(lr=0.01)\n",
        "\n",
        "# ds_train = get_training_dataset(True)\n",
        "# ds_validation = get_validation_dataset()\n"
      ],
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7hGNHuw0w0p"
      },
      "source": [
        "# history = model.fit(ds_train,\n",
        "#                 steps_per_epoch=steps_per_epoch, epochs=15,\n",
        "#                 validation_data=ds_validation, \n",
        "#                 validation_steps=validation_steps,\n",
        "#                 callbacks=callbacks\n",
        "#                 )"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZEZhAe-moJ5"
      },
      "source": [
        ""
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUkOOaSmmn-9"
      },
      "source": [
        ""
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzDq4-mC_c61"
      },
      "source": [
        "# model.save('model.h5')\n",
        "# !cp $filepath '/content/drive/MyDrive/Files/dermasync/model_tfr.h5'"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MfA-ZmLQ0Fr"
      },
      "source": [
        "from sklearn.metrics import precision_score, accuracy_score, confusion_matrix, classification_report \n",
        "def get_report(df=df_test, name='Report', top_k=True, k=5):\n",
        "    print(f'{name}')\n",
        "    batches = get_batches_test(df)\n",
        "    y_true = np.array(batches.classes)\n",
        "    pred_images = y_pred = y_proba = model.predict(batches, verbose=1)\n",
        "    y_pred = np.argmax(y_pred, axis=1)\n",
        "    label2idx = batches.class_indices\n",
        "    idx2label = {v:k for k, v in label2idx.items()}\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    if top_k:\n",
        "        get_top_k_acc(k, y_true, y_proba)\n",
        "\n",
        "# ## converting y to categorical\n",
        "def get_top_k_acc(k, y_true, pred_images):\n",
        "    pred_true = np.zeros((len(y_true), len(skin_labels)))\n",
        "    for i, n in enumerate(y_true):\n",
        "        pred_true[i][n] = 1\n",
        "    for k in range(1, k+1):\n",
        "        kacc = tf.keras.metrics.top_k_categorical_accuracy(pred_true, pred_images, k=k).numpy()\n",
        "        acc = sum(kacc) / len(kacc)\n",
        "        print(k, ' - ', acc)\n",
        "        # if acc > 0.98: break"
      ],
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsaU-t6Ab2ee"
      },
      "source": [
        "# get_report()"
      ],
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvm-gsKiNhFO"
      },
      "source": [
        "# batches = get_validation_dataset()\n",
        "# model.evaluate(batches, steps=10)"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7jmsbwzYruB"
      },
      "source": [
        "# More"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvRm96wHvbJM"
      },
      "source": [
        "## Tsne vis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4llQ_r6vaSx"
      },
      "source": [
        ""
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56txEDZMY3Rt"
      },
      "source": [
        "# def merge_batches(n, batch):\n",
        "#     list_X, list_y = [], []\n",
        "#     for _ in range(n):\n",
        "#         X, y = next(batch)\n",
        "#         X = X.reshape(X.shape[0], -1)\n",
        "#         list_X.append(X)\n",
        "#         y = [np.argmax(i) for i in y]\n",
        "#         list_y.extend(y)\n",
        "#     return np.concatenate(list_X), list_y"
      ],
      "execution_count": 376,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-AC-z2f-fiJ"
      },
      "source": [
        "# m = {idx: val for val, idx in batches_train.class_indices.items()}"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x3eqLCj-KWX"
      },
      "source": [
        "# X, y = merge_batches(30, batches_train)\n",
        "# X.shape, len(y)"
      ],
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrAuS3jN83lH"
      },
      "source": [
        "# X, y = pd.DataFrame(X), pd.DataFrame(y)\n",
        "# df = X\n",
        "# df['label'] = y"
      ],
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-wIQkAr9pl1"
      },
      "source": [
        "# import time\n",
        "\n",
        "# from sklearn.manifold import TSNE\n",
        "# from cuml.manifold import TSNE\n",
        "# #n_sne = 7000\n",
        "\n",
        "# time_start = time.time()\n",
        "# tsne = TSNE(n_iter=10)\n",
        "# tsne_results = tsne.fit_transform(df.values)\n",
        "\n",
        "# print ('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
        "\n"
      ],
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb0XHSLU9puC"
      },
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# # Create the figure\n",
        "# fig = plt.figure( figsize=(8,8) )\n",
        "# ax = fig.add_subplot(1, 1, 1, title='TSNE' )\n",
        "# # Create the scatter\n",
        "# ax.scatter(\n",
        "#     x=tsne_results[:,0], \n",
        "#     y=tsne_results[:,1], \n",
        "#     c=df['label'], \n",
        "#     cmap=plt.cm.get_cmap('Paired'), \n",
        "#     alpha=0.4)\n",
        "# plt.show()"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Hxfn379p1Z"
      },
      "source": [
        ""
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTr4TanKkMQ5"
      },
      "source": [
        "## not working\n",
        "### model tf 2.4 to tf2.1 for pc\n",
        "\n",
        "# %%capture\n",
        "# !pip3 install \n",
        "# !virtualenv env\n",
        "# pathenv = '/content/env/bin/activate'\n",
        "\n",
        "# model_json = model.to_json()\n",
        "# with open(\"model.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# # serialize weights to HDF5\n",
        "# model.save_weights(\"modelweight.h5\")\n",
        "# print(\"Saved model to disk\")"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooz2W5QSEPtp"
      },
      "source": [
        "# %%capture\n",
        "# !pip3 install tensorflow==2.1\n",
        "# model_pc = get_model()\n",
        "# model_pc.load_weights('model.h5')\n",
        "# model_pc.save('model_pc.h5')\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download('model_pc.h5')"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29Vr6Sx0p1IU"
      },
      "source": [
        ""
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irdp3PI6pZL9"
      },
      "source": [
        "# Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kk7tIw9cOsjO"
      },
      "source": [
        "!pip install --quiet optuna\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "import warnings\n",
        "warnings.filterwarnings(action='once')"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc1r5eqLVGej"
      },
      "source": [
        "ds_train = get_training_dataset(cache=False)\n",
        "ds_validation = get_validation_dataset()"
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7-xiBHgT55O"
      },
      "source": [
        "def add_conv_layers(model, filter, dropout, n_layers=2): # n_layers: cont layers in stack, c: choice\n",
        "    for i in range(n_layers - 1):\n",
        "        model.add(Conv2D(filters = filter, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
        "        model.add(BatchNormalization())\n",
        "    model.add(Conv2D(filters = filter, kernel_size = 5, strides = 2, padding = 'same', activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    # model.add(MaxPool2D(pool_size = (2,2))) # added stride 2 instead\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "def add_dense_layers(model, units, dropout):\n",
        "    model.add(Dense(units, activation = 'relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(dropout))"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIygRZ6f5UkF"
      },
      "source": [
        "History = []\n",
        "\n",
        "def get_model_adv(params_model):\n",
        "    model = create_model_adv(**params_model)\n",
        "\n",
        "    model.compile(Adam(lr=params_model['c_lr']), loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='sparse_categorical_accuracy', verbose=1,\n",
        "                                save_best_only=True, mode='max')\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='sparse_categorical_accuracy', factor=0.5, patience=2,\n",
        "                                verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=3)\n",
        "\n",
        "    callbacks = [reduce_lr, early_stop] # checkpoint\n",
        "\n",
        "    return model, callbacks\n",
        "\n",
        "\n",
        "def create_model_adv(n_conv_layers, n_filters, n_dense_layers, n_dense_units, c_dropout, n_base_layers, **_):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    for i in range(1, n_conv_layers + 1):\n",
        "        add_conv_layers(model, n_filters * i, c_dropout)\n",
        "\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    for i in range(1, n_dense_layers): # n - 1\n",
        "        add_dense_layers(model, n_dense_units, c_dropout)\n",
        "\n",
        "    model.add(Dense(len(skin_labels), activation = 'softmax'))\n",
        "    # n_base_layers\n",
        "    base_model = create_base_model(n_base_layers)\n",
        "    # x = base_model.output\n",
        "    # outputs = model(x)\n",
        "    merged_model = Sequential([base_model,\n",
        "                            #    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                               model])\n",
        "    return merged_model\n",
        "\n",
        "def objective(trial):\n",
        "    joblib.dump(study, 'study.pkl')\n",
        "\n",
        "    n_conv_layers = trial.suggest_categorical('n_conv_layers', [0])\n",
        "    n_filters = trial.suggest_categorical('n_filters', [0])\n",
        "\n",
        "    n_dense_layers = trial.suggest_categorical('n_dense_layers', [2, 3, 4]) # if not skip_optuna else params_best['n_dense_layers']\n",
        "    n_dense_units = trial.suggest_categorical('n_dense_units', [256, 512, 1024]) #if not skip_optuna else params_best['n_dense_units']\n",
        "\n",
        "    n_base_layers = trial.suggest_int('n_base_layers', 0, 6, 2) # if not skip_optuna else params_best['n_base_layers']\n",
        "\n",
        "    c_dropout = trial.suggest_categorical('c_dropout', [0, 0.3, 0.5]) if not skip_optuna else params_best['c_dropout']\n",
        "    c_lr = trial.suggest_loguniform('c_lr', 0.0001, 0.01) if not skip_optuna else params_best['c_lr']\n",
        "\n",
        "    params_model = dict(\n",
        "        n_conv_layers = n_conv_layers,\n",
        "        n_filters = n_filters,\n",
        "        n_dense_layers = n_dense_layers,\n",
        "        n_dense_units = n_dense_units,\n",
        "        c_dropout = c_dropout,\n",
        "        n_base_layers = n_base_layers,\n",
        "        c_lr = c_lr,\n",
        "    )\n",
        "\n",
        "    pruning_callback = optuna.integration.TFKerasPruningCallback(trial, 'val_sparse_categorical_accuracy')\n",
        "\n",
        "    model, callbacks = get_model_adv(params_model)\n",
        "    callbacks += [pruning_callback]\n",
        "    # ds_train = get_training_dataset()\n",
        "    # ds_validation = get_validation_dataset()\n",
        "\n",
        "    history = model.fit(ds_train,\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=8,\n",
        "                    validation_data=ds_validation, \n",
        "                    validation_steps=validation_steps,\n",
        "                    callbacks=callbacks,\n",
        "                    verbose=1)  \n",
        "      \n",
        "    History.append(history)\n",
        "    return history.history['val_sparse_categorical_accuracy'][-1]"
      ],
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGPE8wfFuVGa"
      },
      "source": [
        "import optuna \n",
        "import joblib\n",
        "\n",
        "skip_optuna = False\n",
        "\n",
        "if os.path.isfile('study.pkl'):\n",
        "    study = joblib.load('study.pkl')\n",
        "else:\n",
        "    study = optuna.create_study(sampler=optuna.samplers.TPESampler(multivariate=True), direction='maximize')\n",
        "\n",
        "## set values you know well is good\n",
        "# params_best=  {'n_conv_layers': 0, 'n_filters': 0, 'n_dense_layers': 3, 'n_dense_units': 2048, 'n_base_layers': 2, 'c_dropout': 0.5, 'c_lr': 0.005}\n",
        "\n",
        "# study.enqueue_trial(params_best)\n",
        "\n",
        "# study.optimize(objective, n_trials=25, timeout=3600)"
      ],
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnA2YQWwKWt7"
      },
      "source": [
        "from tensorflow.keras import Sequential"
      ],
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I_8jPHnXCQb"
      },
      "source": [
        "# !cp study.pkl $path_drive_data\n",
        "# df = study.trials_dataframe()\n",
        "# df.head(3)"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jENRN-0bMeq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b23860-e462-460d-d77d-015250c36065"
      },
      "source": [
        "trial = study.best_trial\n",
        "params_best = trial.params\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6666666865348816\n",
            "Best hyperparameters: {'n_conv_layers': 0, 'n_filters': 0, 'n_dense_layers': 2, 'n_dense_units': 512, 'n_base_layers': 2, 'c_dropout': 0.5, 'c_lr': 0.00016699936123254085}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYAIOZoPgYWp"
      },
      "source": [
        "# optuna.visualization.plot_optimization_history(study)"
      ],
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ql9-VPngYWq"
      },
      "source": [
        "# optuna.visualization.plot_slice(study)"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz-L-r3ogYWq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58376d38-a794-4206-99b0-e157e8d9511c"
      },
      "source": [
        "params_best=  {'n_conv_layers': 0, 'n_filters': 0, 'n_dense_layers': 3, 'n_dense_units': 1024, 'n_base_layers': 0, 'c_dropout': 0, 'c_lr': 0.001}\n",
        "print(params_best)\n",
        "# model, _ = get_model_adv(params_best)"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_conv_layers': 0, 'n_filters': 0, 'n_dense_layers': 3, 'n_dense_units': 1024, 'n_base_layers': 0, 'c_dropout': 0, 'c_lr': 0.001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkmpymRu1DoH"
      },
      "source": [
        "# model = tf.keras.models.load_model('model_36class.h5')"
      ],
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atigEgjfU6TB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b48f5e-9c75-42fc-a8dd-1e716e315a38"
      },
      "source": [
        "reduce_lr = ReduceLROnPlateau(monitor='sparse_categorical_accuracy', factor=0.5, patience=2,\n",
        "                            verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_sparse_categorical_accuracy', patience=5)\n",
        "\n",
        "callbacks = [reduce_lr, early_stop]\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(ds_train,\n",
        "                steps_per_epoch=steps_per_epoch,\n",
        "                epochs=25,\n",
        "                validation_data=ds_validation, \n",
        "                validation_steps=validation_steps,\n",
        "                callbacks=callbacks,\n",
        "                verbose=1) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "197/197 [==============================] - 42s 195ms/step - loss: 1.7945 - sparse_categorical_accuracy: 0.6066 - val_loss: 1.3080 - val_sparse_categorical_accuracy: 0.6623\n",
            "Epoch 2/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 1.1737 - sparse_categorical_accuracy: 0.7015 - val_loss: 1.0399 - val_sparse_categorical_accuracy: 0.7390\n",
            "Epoch 3/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.7889 - sparse_categorical_accuracy: 0.7920 - val_loss: 0.8235 - val_sparse_categorical_accuracy: 0.7974\n",
            "Epoch 4/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.6512 - sparse_categorical_accuracy: 0.8258 - val_loss: 0.7478 - val_sparse_categorical_accuracy: 0.8169\n",
            "Epoch 5/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.4697 - sparse_categorical_accuracy: 0.8774 - val_loss: 0.6683 - val_sparse_categorical_accuracy: 0.8390\n",
            "Epoch 6/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.4392 - sparse_categorical_accuracy: 0.8804 - val_loss: 0.5962 - val_sparse_categorical_accuracy: 0.8662\n",
            "Epoch 7/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.3666 - sparse_categorical_accuracy: 0.9017 - val_loss: 0.5909 - val_sparse_categorical_accuracy: 0.8675\n",
            "Epoch 8/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.3173 - sparse_categorical_accuracy: 0.9156 - val_loss: 0.5106 - val_sparse_categorical_accuracy: 0.8831\n",
            "Epoch 9/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.2980 - sparse_categorical_accuracy: 0.9179 - val_loss: 0.5592 - val_sparse_categorical_accuracy: 0.8792\n",
            "Epoch 10/25\n",
            "197/197 [==============================] - 38s 192ms/step - loss: 0.2482 - sparse_categorical_accuracy: 0.9339 - val_loss: 0.5954 - val_sparse_categorical_accuracy: 0.8779\n",
            "Epoch 11/25\n",
            "197/197 [==============================] - 38s 191ms/step - loss: 0.2613 - sparse_categorical_accuracy: 0.9283 - val_loss: 0.6982 - val_sparse_categorical_accuracy: 0.8727\n",
            "Epoch 12/25\n",
            "197/197 [==============================] - 38s 192ms/step - loss: 0.2091 - sparse_categorical_accuracy: 0.9421 - val_loss: 0.6233 - val_sparse_categorical_accuracy: 0.8844\n",
            "Epoch 13/25\n",
            "112/197 [================>.............] - ETA: 15s - loss: 0.2292 - sparse_categorical_accuracy: 0.9370"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ku3IdueYqoz"
      },
      "source": [
        "model.evaluate(ds_train, steps=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp1pux1dkTgP"
      },
      "source": [
        "model.evaluate(ds_validation, steps=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDTx5aXefWyR"
      },
      "source": [
        "def get_report_tf(ds, steps, k=5):\n",
        "    y_true = []\n",
        "    y_proba = []\n",
        "    ds_iter = iter(ds)\n",
        "    for i in range(steps):\n",
        "        images, labels = next(ds_iter)\n",
        "        y_true.extend([x.numpy() for x in labels])\n",
        "        proba = model.predict(images)\n",
        "        y_proba.extend(proba)\n",
        "    y_pred = np.argmax(y_proba, axis=1)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    if k:\n",
        "        get_top_k_acc(k, y_true, y_proba)\n",
        "\n",
        "ds = get_validation_dataset()\n",
        "get_report_tf(ds, steps=validation_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hgdGF_Ul4lu"
      },
      "source": [
        "get_report(df_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uenGFIyou84h"
      },
      "source": [
        "model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vblnUxdFvwkg"
      },
      "source": [
        "# !cp model_36class.h5 $path_drive_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv06CAZQw7Na"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfSUKh_ZxDeO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}